{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeU25AnsCQYG"
      },
      "source": [
        "<font size=8>  Setting up the Collection Space Navigator\n",
        "\n",
        "In this How-To guide you will produce all necessary files to create a custom version of the Collection Space Navigator (CSN).\n",
        "\n",
        "Project link: https://collection-space-navigator.github.io/ \n",
        "\n",
        "> Note: We highly recommend to first get familiar with the example collection before trying your with your own data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcWeuOxUCQYI"
      },
      "source": [
        "<font size=6> 1) Prepare Collection Data\n",
        "\n",
        "Loads the dataset and sets up the metadata.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "w25_J6m4CQYJ"
      },
      "outputs": [],
      "source": [
        "#@title Import Libraries\n",
        "#@markdown Installs all necessary libraries! Optional libraries will be installed only if needed.\n",
        "\n",
        "import json, math, os, io\n",
        "\n",
        "try:\n",
        "  import pandas as pd\n",
        "except:\n",
        "  print(\"Installing pandas via Pip\")\n",
        "  !pip install pandas --quiet\n",
        "  import pandas as pd\n",
        "\n",
        "try:\n",
        "  import numpy as np\n",
        "except:\n",
        "  print(\"Installing numpy via Pip\")\n",
        "  !pip install numpy --quiet\n",
        "  import numpy as np\n",
        "\n",
        "try:\n",
        "  from tqdm import tqdm\n",
        "except:\n",
        "  print(\"Installing tqdm via Pip\")\n",
        "  !pip install tqdm --quiet\n",
        "  from tqdm import tqdm\n",
        "\n",
        "try:\n",
        "  import ipywidgets as widgets\n",
        "  from ipywidgets import interactive,HBox,VBox,Label\n",
        "except:\n",
        "  print(\"Installing ipywidgets via Pip\")\n",
        "  !pip install ipywidgets --quiet\n",
        "  import ipywidgets as widgets\n",
        "  from ipywidgets import interactive,HBox,VBox,Label\n",
        "\n",
        "try:\n",
        "  from IPython.display import display\n",
        "except:\n",
        "  print(\"Installing IPython via Pip\")\n",
        "  !pip install ipython --quiet\n",
        "  from IPython.display import display\n",
        "\n",
        "try:\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "except:\n",
        "  print(\"Installing sklearn via Pip\")\n",
        "  !pip install sklearn --quiet\n",
        "  from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DFnzOTdddIAH"
      },
      "outputs": [],
      "source": [
        "#@title (optional) Mount Google Drive\n",
        "#@markdown >Note: This is not necessary if you work with example data. Mounting Google Drive gives your Colab Notebook instance access to your data, and does not share access with the CSN authors.\n",
        "def mount_gdrive(v):\n",
        "    try:\n",
        "      from google.colab import drive\n",
        "      # drive.mount(drive_path,force_remount=False)\n",
        "      buttonGDrive.description=\"mounting...\"\n",
        "      buttonGDrive.disabled=True\n",
        "      drive.mount('/content/gdrive',force_remount=True)\n",
        "    except:\n",
        "      print(\"...error mounting drive\")\n",
        "      buttonGDrive.description=\"mounting failed!\"\n",
        "    else:\n",
        "      buttonGDrive.description=\"successfully mounted\"\n",
        "\n",
        "layoutButtons = {'width': '210px'}\n",
        "buttonGDrive = widgets.Button(description='mount Google Drive',icon='check',indent=True,layout=layoutButtons)\n",
        "buttonGDrive.on_click(mount_gdrive)\n",
        "\n",
        "display(buttonGDrive)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r6jZRVHhCQYK",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "#@title Define INPUT\n",
        "#@markdown >Note: Running this cell opens a dialog in which the input data can be defined. Use the provided example data (recommended first) or your own.\n",
        "\n",
        "\n",
        "style = {'description_width': '250px'}\n",
        "layout = {'width': '600px', 'justify-content': 'lex-satrt'}\n",
        "# layoutButtons = {'width': '210px'}\n",
        "useExample = widgets.Checkbox(value=True,description='use example data',indent=True)\n",
        "datasetTitle = widgets.Text(placeholder='title of the dataset', description='Title:', style=style, layout=layout, value = \"Testset\")\n",
        "description = widgets.Textarea(placeholder='Short description of the dataset and method(s)', description='Description (optional):', style=style, layout=layout, value=\"\")\n",
        "embeddingsLocation = widgets.Text(placeholder='path to embeddings file (.csv)', description='Embeddings Filepath (optional):', style=style, layout=layout, value = \"CSN/example_data/embeddings_testset.csv\")\n",
        "metadataLocation = widgets.Text(placeholder='path to metadata file (.csv)', description='Metadata Filepath:', style=style, layout=layout, value = \"CSN/example_data/metadata_testset.csv\")\n",
        "imageLocation = widgets.Text(placeholder='path to image collection folder', description='Image Folder:', style=style, layout=layout, value = \"CSN/example_data/testset_images/\")\n",
        "imageWebLocation = widgets.Text(placeholder='URL prefix to public image directory', description='Image URL prefix:',style=style, layout=layout, value =  \"https://github.com/Collection-Space-Navigator/CSN/raw/main/example_data/testset_images/\")\n",
        "# buildTool = widgets.RadioButtons(options=[('create new tool and dataset',1), ('add new dataset to existing tool',2)],value=1,description='Building:',style=style, layout=layout)\n",
        "# uploadFile = widgets.FileUpload(accept='.json',multiple=False,description=\"upload 'datasets_config.json'\", layout=layoutButtons)\n",
        "# buttonGDrive = widgets.Button(description='mount Google Drive',icon='check',indent=True,layout=layoutButtons)\n",
        "# buttonGDrive.on_click(mount_gdrive)\n",
        "# i = interactive(getOptions, BUILD = buildTool)\n",
        "if os.path.exists(\"/content/gdrive/MyDrive/\"):\n",
        "    imageLocation.value = \"/content/gdrive/MyDrive/CSN/example_data/testset_images/\"\n",
        "    embeddingsLocation.value = \"/content/gdrive/MyDrive/CSN/example_data/embeddings_testset.csv\"\n",
        "    metadataLocation.value = \"/content/gdrive/MyDrive/CSN/example_data/metadata_testset.csv\"  \n",
        "else:\n",
        "    imageLocation.value = \"CSN/example_data/testset_images/\"\n",
        "    embeddingsLocation.value = \"CSN/example_data/embeddings_testset.csv\"\n",
        "    metadataLocation.value = \"CSN/example_data/metadata_testset.csv\"  \n",
        "\n",
        "imageWebLocation.value =  \"https://github.com/Collection-Space-Navigator/CSN/raw/main/example_data/testset_images/\"\n",
        "\n",
        "\n",
        "subset = widgets.Checkbox(value=False,description='make subset',indent=True)\n",
        "subsetSize = widgets.BoundedIntText(value=2048,min=10,max=9999999, step=1,description='Subset size:')\n",
        "def makeSubset(SUBSET):\n",
        "    if SUBSET:\n",
        "        display(subsetSize)\n",
        "    else:\n",
        "        subsetSize.value == None\n",
        "i = interactive(makeSubset, SUBSET = subset)\n",
        "left = VBox([datasetTitle, description, embeddingsLocation, metadataLocation, imageLocation, imageWebLocation])\n",
        "right = VBox([useExample, i])\n",
        "display(HBox([left,right]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tHhLCEWOykFu"
      },
      "outputs": [],
      "source": [
        "#@title Load INPUT files\n",
        "#@markdown Loads and checks all files.\n",
        "\n",
        "#@markdown >Note: Example data will be downloaded only if needed.\n",
        "\n",
        "if useExample.value == True:\n",
        "\n",
        "  if os.path.exists(\"gdrive/MyDrive/\"):\n",
        "    print(\"using gdrive/MyDrive\")\n",
        "    %cd gdrive/MyDrive\n",
        "\n",
        "  if not os.path.exists(\"CSN\"):\n",
        "    os.makedirs(\"CSN\")\n",
        "    print(\"created new directory 'CSN'\")\n",
        "  %cd CSN\n",
        "  try:\n",
        "    !git init\n",
        "    !git remote add -f origin https://github.com/Collection-Space-Navigator/CSN\n",
        "    !git config core.sparseCheckout true\n",
        "    !echo \"example_data\" >> .git/info/sparse-checkout\n",
        "    print(\"downloading example dataset...\")\n",
        "    !git pull origin main\n",
        "    print(\"...done\")\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "  %cd -\n",
        "\n",
        "imagNumb = len(os.listdir(imageLocation.value))\n",
        "print(f'found {imagNumb} files in {imageLocation.value}')\n",
        "\n",
        "metadata = pd.read_csv(metadataLocation.value, skipinitialspace=True)\n",
        "if subset:\n",
        "    metadata = metadata[:subsetSize.value]\n",
        "metaNumb = len(metadata)\n",
        "print(f'found {metaNumb} entries in {metadataLocation.value}')\n",
        "\n",
        "if embeddingsLocation.value != \"\":\n",
        "  embeddings = pd.read_csv(embeddingsLocation.value, skipinitialspace=True)\n",
        "  embeddings = embeddings.loc[:, embeddings.columns!='id']\n",
        "  if subset:\n",
        "    embeddings = embeddings[:subsetSize.value]\n",
        "  vecNumb = len(embeddings)\n",
        "  print(f'found {vecNumb} entries in {embeddingsLocation.value}')\n",
        "\n",
        "  if metaNumb == vecNumb:\n",
        "    if vecNumb <= imagNumb:\n",
        "      print(\"Looks ok.\")\n",
        "      print()\n",
        "      print(f'Embedding file contains {vecNumb} vectors in {len(embeddings.columns)} dimensions.')\n",
        "      print(\"Metadata Head:\")\n",
        "      print(metadata.head())\n",
        "    else:\n",
        "      print()\n",
        "      print(\"ERROR: number of images is smaller than number of vectors\")\n",
        "\n",
        "if metaNumb <= imagNumb:\n",
        "  print(\"Looks ok.\")\n",
        "  print(\"Metadata Head:\")\n",
        "  print(metadata.head())\n",
        "else:\n",
        "  print()\n",
        "  print(\"ERROR: number of images and metadata elements don't match!\")\n",
        "foldername = datasetTitle.value.lower().replace(\" \",\"_\")\n",
        "print()\n",
        "print(f'Creating new dataset directory: CSN/{foldername}...')\n",
        "if not os.path.exists(f\"CSN/{foldername}\"):\n",
        "    os.makedirs(f\"CSN/{foldername}\")\n",
        "    print(\"... success\")\n",
        "else:\n",
        "    print(\"... folder already exists (might overwrite existing files)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AtOUyvwapOfx"
      },
      "outputs": [],
      "source": [
        "#@title Assign metadata fields\n",
        "#@markdown Choose which field names in the metadata file should be used.   \n",
        "\n",
        "#@markdown >Note: Select multiple values using shift+ctrl+mouseclick, shift+command+mouseclick, or shift+arrow keys.\n",
        "\n",
        "\n",
        "filenameColumn = widgets.Dropdown(description=\"Image filenames (JPG or PNG):\",options=[mf for mf in metadata.columns if pd.api.types.is_string_dtype(metadata[mf]) and metadata[mf].str.endswith((\".jpg\",\".JPEG\",\"JPG\",\".jpeg\",\".png\",\".PNG\")).all()], style=style, layout=layout)\n",
        "classColumns = widgets.SelectMultiple(options=[mf for mf in metadata.columns if pd.api.types.is_integer_dtype(metadata[mf]) and mf != \"index\"],description='optional: Cluster data (integers):', style=style, layout=layout)\n",
        "infoColumns = widgets.SelectMultiple(options=[mf for mf in metadata.columns if mf != \"index\"],description='Info fields (display in preview):', style=style, layout=layout)\n",
        "sliderColumns = widgets.SelectMultiple(options=[mf for mf in metadata.columns if pd.api.types.is_numeric_dtype(metadata[mf]) and mf != \"index\"],description='Slider data (floats or integers):', style=style, layout=layout)\n",
        "filterColumns = widgets.SelectMultiple(options=[mf for mf in metadata.columns if pd.api.types.is_string_dtype(metadata[mf]) and mf != 'URL'],description='optional: Filter & Search fields (string):', style=style, layout=layout)\n",
        "if useExample.value == True:\n",
        "  infoColumns.value = (\"Prompt\", \"Colors\", \"Contrast\", \"File Size\")\n",
        "  sliderColumns.value = (\"Colorfulness\", \"Colors\", \"Contrast\", \"File Size\")\n",
        "  filterColumns.value = (\"Prompt\",)\n",
        "  classColumns.value = (\"Class\",)\n",
        "left = VBox([filenameColumn, infoColumns, sliderColumns])\n",
        "right = VBox([filterColumns, classColumns])\n",
        "display(HBox([left,right]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------"
      ],
      "metadata": {
        "id": "IJ29FLXmpIKT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OHuwVEJlZFj"
      },
      "source": [
        "<font size=6> 2) Prepare Image Data\n",
        "\n",
        "To handle large amounts of images efficiently, the CSN uses sprite sheets with multiple thumbnails behind the scenes. These sprite-sheets need to be generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pBSPbVtXCQYU"
      },
      "outputs": [],
      "source": [
        "#@title Generate sprite sheets\n",
        "#@markdown > Note: only needed for new datasets or to update existing tiles (skip this part if you already generated them)\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# parameters for tiles\n",
        "tileSize = 2048  # size of tile\n",
        "tileRows = 32  # rows per tile\n",
        "columns = tileRows  # columns per |tile\n",
        "squareSize = int(tileSize/tileRows)\n",
        "imgPerTile = tileRows*columns\n",
        "numbTiles = math.ceil(len(metadata)/imgPerTile)\n",
        "\n",
        "\n",
        "\n",
        "def resizeImgTile(image, squareSize):\n",
        "    (w,h) = image.size\n",
        "    max_dim = max(w, h)\n",
        "    new_w = int(w/max_dim*squareSize)\n",
        "    new_h = int(h/max_dim*squareSize)\n",
        "    x_dif = int((squareSize - new_w) / 2)\n",
        "    y_dif = int((squareSize - new_h) / 2)\n",
        "    return image.resize((new_w-8, new_h-8), Image.ANTIALIAS),new_w,new_h,x_dif,y_dif\n",
        "\n",
        "def generateTiles(ImgPaths,foldername,IMAGE_FOLDER, tileSize=2048, tileRows=32):\n",
        "    # Create output folder if it doesn't exist\n",
        "    os.makedirs(f\"CSN/{foldername}\", exist_ok=True)\n",
        "    \n",
        "    # Parameters for tiles\n",
        "    squareSize = int(tileSize/tileRows)\n",
        "    imgPerTile = tileRows*tileRows\n",
        "    numbTiles = math.ceil(len(ImgPaths)/imgPerTile)\n",
        "    \n",
        "    for tileNum in tqdm(range(numbTiles), desc = \"Generating tiles\"):\n",
        "        result = Image.new(\"RGBA\", (tileSize, tileSize), (255, 0, 0, 0))\n",
        "        currentIDX = 0\n",
        "        for i in range(imgPerTile):\n",
        "            img_idx = i+(tileNum*imgPerTile)\n",
        "            if img_idx >= len(ImgPaths):\n",
        "                break\n",
        "            entry = ImgPaths[img_idx]\n",
        "            try:\n",
        "                image = Image.open(os.path.join(IMAGE_FOLDER, entry))\n",
        "                # print(entry)\n",
        "            except:\n",
        "                print(f\"Skipping invalid image file: {entry}\")\n",
        "                continue\n",
        "            resizedImage,w,h,x_dif,y_dif = resizeImgTile(image, squareSize)\n",
        "            r_result = Image.new(\"RGBA\", (w, h), (1, 1, 1, 1))   # produces an almost transparent border to indicate clusters in the tool\n",
        "            r_result.paste(resizedImage, (4,4))\n",
        "            x = i % tileRows * squareSize + x_dif\n",
        "            y = i // tileRows * squareSize + y_dif\n",
        "            result.paste(r_result, (x, y, x + w, y + h))\n",
        "        result = result.resize((tileSize, tileSize), Image.ANTIALIAS)\n",
        "        # convert to 256 colors for faster loading online\n",
        "        result = result.convert(\"P\", palette=Image.ADAPTIVE, colors=256)\n",
        "        result.save(f'CSN/{foldername}/tile_{tileNum}.png', \"PNG\", optimize=True)    \n",
        "\n",
        "generateTiles(metadata[filenameColumn.value],foldername,imageLocation.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------"
      ],
      "metadata": {
        "id": "qUD79KzapGlx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvsa4czdCQYV"
      },
      "source": [
        "<font size=6> 3) Generate Mappings\n",
        "\n",
        "Mappings are plots containing 2D coordinates (x,y) of the image objects. \n",
        "\n",
        "Here are several methods you can run. The Collection Space Navigator can handle many mappings but needs at least one to work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DtVqZb6CT-p_"
      },
      "outputs": [],
      "source": [
        "#@title Prepare for mappings\n",
        "#@markdown loads the normalization and scaling functions necessary for the steps below.\n",
        "# Normalization and Scaling\n",
        "mappings = []\n",
        "minScale = -25\n",
        "maxScale = 25\n",
        "\n",
        "def normalize(embeddings):\n",
        "    minX = min(embeddings, key=lambda x: x[0])[0]\n",
        "    rangeX = max(embeddings, key=lambda x: x[0])[0] - minX\n",
        "    minY = min(embeddings, key=lambda x: x[1])[1]\n",
        "    rangeY = max(embeddings, key=lambda x: x[1])[1] - minY\n",
        "    rangeScale = maxScale + 0.9999999999 - minScale\n",
        "    for index, e in enumerate(embeddings):\n",
        "        embeddings[index][0] =  (embeddings[index][0] - minX) / rangeX * rangeScale + minScale\n",
        "        embeddings[index][1] = (embeddings[index][1] - minY) / rangeY * rangeScale + minScale\n",
        "    return embeddings\n",
        "\n",
        "def centerEmbeddings(embeddings):\n",
        "    offsetA = (max(embeddings, key=lambda x: x[0])[0] + min(embeddings, key=lambda x: x[0])[0]) / 2\n",
        "    offsetB = (max(embeddings, key=lambda x: x[1])[1] + min(embeddings, key=lambda x: x[1])[1]) / 2\n",
        "    for index, e in enumerate(embeddings):\n",
        "        embeddings[index][0] = embeddings[index][0] - offsetA\n",
        "        embeddings[index][1] = embeddings[index][1] - offsetB\n",
        "    return embeddings\n",
        "    \n",
        "class NumpyEncoder(json.JSONEncoder):\n",
        "    \"\"\" Special json encoder for numpy types \"\"\"\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return json.JSONEncoder.default(self, obj)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=5> 3.1 From metadata (optional)"
      ],
      "metadata": {
        "id": "LsI4HATziR69"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9sg3a8k_CQYY"
      },
      "outputs": [],
      "source": [
        "#@title (optional) Create 2D plots\n",
        "#@markdown Choose 2 metadadata fields (float or integer) and click \"make plot\". Repeat for every combination you want to add.\n",
        "#@markdown >Note: Running this step opens a dialog in which you can chose X and Y dimensions from the available data and create additional 2D plots\n",
        "\n",
        "def makePlot(v):\n",
        "  A = AColumn.value\n",
        "  B = BColumn.value\n",
        "  plot = metadata[[A,B]]\n",
        "  normalizedPlot = normalize(plot.values)\n",
        "  centeredEmbedding = centerEmbeddings(normalizedPlot)\n",
        "  filename = (A + \"_\" + B).replace(\" \",\"\")\n",
        "  # save file\n",
        "  with open(f'CSN/{foldername}/{filename}.json', \"w\") as out_file:\n",
        "    out = json.dumps(centeredEmbedding, cls=NumpyEncoder)\n",
        "    out_file.write(out)\n",
        "  print(f\"saved {filename}.json\")\n",
        "  mappings.append({\"name\": filename, \"file\": filename + \".json\"})\n",
        "\n",
        "AColumn = widgets.Dropdown(description=\"x-axis:\",options=[mf for mf in metadata.columns if pd.api.types.is_numeric_dtype(metadata[mf]) and mf != \"index\"], style=style, layout=layout)\n",
        "BColumn = widgets.Dropdown(description=\"y-axis:\",options=[mf for mf in metadata.columns if pd.api.types.is_numeric_dtype(metadata[mf]) and mf != \"index\"], style=style, layout=layout)\n",
        "button2DPlot = widgets.Button(description='make plot',icon='check')\n",
        "button2DPlot.on_click(makePlot)\n",
        "left = VBox([AColumn,BColumn])\n",
        "right = VBox([button2DPlot])\n",
        "HBox([left,right])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=5> 3.2 From embeddings (optional)"
      ],
      "metadata": {
        "id": "TdAkDgquhU73"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IBwRz1RYnpUr"
      },
      "outputs": [],
      "source": [
        "#@title (optional) Run Principal Component Analysis (PCA)\n",
        "components = 5 #@param {type:\"number\"}\n",
        "add_slider = True #@param {type:\"boolean\"}\n",
        "#@markdown >See PCA documentation: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.eA.html\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def generate_PC(df,n,scale):\n",
        "    print(\"performing PCA...\")\n",
        "    x = StandardScaler().fit_transform(df)\n",
        "    pca = PCA(n_components=n)\n",
        "    embedding = pca.fit_transform(x)\n",
        "    if scale == True:\n",
        "      normalized = normalize(embedding)\n",
        "      centeredEmbedding = centerEmbeddings(normalized)\n",
        "    else:\n",
        "      centeredEmbedding = embedding\n",
        "    print(\"...done\")\n",
        "    return centeredEmbedding\n",
        "\n",
        "PCAEembedding = generate_PC(embeddings,components,True)\n",
        "PCMap = PCAEembedding.reshape(-1,2)\n",
        "\n",
        "\n",
        "# save file\n",
        "with open(f'CSN/{foldername}/PCA.json', \"w\") as out_file:\n",
        "    out = json.dumps(PCMap, cls=NumpyEncoder)\n",
        "    out_file.write(out)\n",
        "print(f\"saved PCA.json\")\n",
        "mappings.append({\"name\": \"PCA\", \"file\": \"PCA.json\"})\n",
        "\n",
        "# add columns to metadata for each component\n",
        "for i in range(components):\n",
        "  metadata[f\"PC{i+1}\"] = PCAEembedding[:,i]\n",
        "  print(f\"... added PC{i+1} to metadata\")\n",
        "\n",
        "# add slider for each component\n",
        "if add_slider:\n",
        "  sliderCols = list(sliderColumns.value)\n",
        "  for i in range(components):\n",
        "    sliderCols.append(f\"PC{i+1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GrJqZPjYCQYW"
      },
      "outputs": [],
      "source": [
        "#@title (optional) Run UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction\n",
        "n_neighbors=15 #@param {type:\"number\"}\n",
        "min_dist=0.18 #@param {type:\"number\"}\n",
        "metric=\"correlation\" #@param {type:\"string\"}\n",
        "verbose=True #@param {type:\"boolean\"}\n",
        "#@markdown >See UMAP documentation: https://umap-learn.readthedocs.io/en/latest/\n",
        "\n",
        "\n",
        "try:\n",
        "  import umap.umap_ as umap\n",
        "except:\n",
        "  print(\"Installing umap-learn via Pip\")\n",
        "  !pip install umap-learn --quiet\n",
        "  import umap.umap_ as umap\n",
        "\n",
        "def generateUMAP(df):\n",
        "    print(\"generating UMAP...\")\n",
        "    scaled_penguin_data = StandardScaler().fit_transform(df)\n",
        "    reducer = umap.UMAP(n_neighbors=n_neighbors,\n",
        "                        min_dist=min_dist,\n",
        "                        metric=metric,\n",
        "                        verbose=verbose)\n",
        "    embedding = reducer.fit_transform(scaled_penguin_data)\n",
        "    normalized = normalize(embedding)\n",
        "    centeredEmbedding = centerEmbeddings(normalized)\n",
        "    print(\"...done\")\n",
        "    return centeredEmbedding\n",
        "\n",
        "fullEmbeddings = generateUMAP(embeddings)\n",
        "# save file\n",
        "with open(f'CSN/{foldername}/UMAP.json', \"w\") as out_file:\n",
        "    out = json.dumps(fullEmbeddings, cls=NumpyEncoder)\n",
        "    out_file.write(out)\n",
        "print(f\"saved UMAP.json\")\n",
        "mappings.append({\"name\": \"UMAP\", \"file\": \"UMAP.json\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0NlqxmzVCQYX"
      },
      "outputs": [],
      "source": [
        "#@title (optional) Run t-SNE: t-distributed Stochastic Neighbor Embedding\n",
        "n_components = 2 #@param {type:\"number\"}\n",
        "verbose = 1 #@param {type:\"number\"}\n",
        "random_state = 123 #@param {type:\"number\"}\n",
        "#@markdown >See t-SNE documentation: https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def generateTSNE(df):\n",
        "    print(\"generating t-SNE...\")\n",
        "    x = StandardScaler().fit_transform(df)\n",
        "    tsne = TSNE(n_components=n_components, verbose=verbose, random_state=random_state)\n",
        "    embedding = tsne.fit_transform(x)\n",
        "    normalized = normalize(embedding)\n",
        "    centeredEmbedding = centerEmbeddings(normalized)\n",
        "    print(\"...done\")\n",
        "    return centeredEmbedding\n",
        "\n",
        "tsneEembedding = generateTSNE(embeddings)\n",
        "# save file\n",
        "with open(f'CSN/{foldername}/tSNE.json', \"w\") as out_file:\n",
        "    out = json.dumps(tsneEembedding, cls=NumpyEncoder)\n",
        "    out_file.write(out)\n",
        "print(f\"saved tSNE.json\")\n",
        "mappings.append({\"name\": \"t-SNE\", \"file\": \"tSNE.json\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (optional) Create 2D plots\n",
        "#@markdown Choose 2 metadadata fields (float or integer) and click \"make plot\". Repeat for every combination you want to add.\n",
        "#@markdown >Note: Running this step opens a dialog in which you can chose X and Y dimensions from the available data and create additional 2D plots\n",
        "\n",
        "def makePlot(v):\n",
        "  A = AColumn.value\n",
        "  B = BColumn.value\n",
        "  plot = metadata[[A,B]]\n",
        "  normalizedPlot = normalize(plot.values)\n",
        "  centeredEmbedding = centerEmbeddings(normalizedPlot)\n",
        "  filename = (A + \"_\" + B).replace(\" \",\"\")\n",
        "  # save file\n",
        "  with open(f'CSN/{foldername}/{filename}.json', \"w\") as out_file:\n",
        "    out = json.dumps(centeredEmbedding, cls=NumpyEncoder)\n",
        "    out_file.write(out)\n",
        "  print(f\"saved {filename}.json\")\n",
        "  mappings.append({\"name\": filename, \"file\": filename + \".json\"})\n",
        "\n",
        "AColumn = widgets.Dropdown(description=\"x-axis:\",options=[mf for mf in metadata.columns if pd.api.types.is_numeric_dtype(metadata[mf]) and mf != \"index\"], style=style, layout=layout)\n",
        "BColumn = widgets.Dropdown(description=\"y-axis:\",options=[mf for mf in metadata.columns if pd.api.types.is_numeric_dtype(metadata[mf]) and mf != \"index\"], style=style, layout=layout)\n",
        "button2DPlot = widgets.Button(description='make plot',icon='check')\n",
        "button2DPlot.on_click(makePlot)\n",
        "left = VBox([AColumn,BColumn])\n",
        "right = VBox([button2DPlot])\n",
        "HBox([left,right])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "f5_ucbG2i_te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------"
      ],
      "metadata": {
        "id": "MedpdOTQpEoA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7r2I7QzCQYa"
      },
      "source": [
        "<font size=6> 4) Create Config Files\n",
        "\n",
        "All customization and component settings are defined in the config files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YoSHLl1gCT8H"
      },
      "outputs": [],
      "source": [
        "#@title Set Sliders\n",
        "#@markdown Set the appearance of the range slider elements and histograms.\n",
        "\n",
        "try:\n",
        "  import distinctipy\n",
        "except:\n",
        "  print(\"Installing distinctipy via Pip\")\n",
        "  !pip install distinctipy --quiet\n",
        "  import distinctipy\n",
        "  \n",
        "# check if sliderCols exists\n",
        "try:\n",
        "  sliderCols\n",
        "except NameError:\n",
        "  sliderCols = list(sliderColumns.value)\n",
        "  \n",
        "if len(sliderCols) > 0:    \n",
        "  layoutCol = {'width': '110px'}\n",
        "  sliderColorDict = {}\n",
        "  left = [Label('display name')]\n",
        "  middle = [Label('description text')]\n",
        "  right = [Label('histogram color')]\n",
        "  colors = distinctipy.get_colors(len(sliderCols),pastel_factor=1)\n",
        "  for i, sliderName in enumerate(sliderCols):\n",
        "    sliderColorDict[sliderName] = widgets.ColorPicker(concise=False,value=distinctipy.get_hex(colors[i]),layout=layoutCol)\n",
        "    right.append(sliderColorDict[sliderName])\n",
        "  sliderInfoDict = {}\n",
        "  for sliderName in sliderCols:\n",
        "    sliderInfoDict[sliderName] = widgets.Text(placeholder=\"info text for slider\",layout=layout)\n",
        "    middle.append(sliderInfoDict[sliderName])\n",
        "  sliderNameDict = {}\n",
        "  for sliderName in sliderCols:\n",
        "    sliderNameDict[sliderName] = widgets.Text(placeholder=\"name of slider\",value=sliderName)\n",
        "    left.append(sliderNameDict[sliderName])\n",
        "  print(\"\\nSlider Settings:\\n\") \n",
        "  idx = VBox([Label('')]+[Label(f\"{n}:\") for n in sliderCols])\n",
        "  left_box = VBox([l for l in left])\n",
        "  middle_box = VBox([m for m in middle])\n",
        "  right_box = VBox([r for r in right])\n",
        "  display(HBox([idx,left_box,middle_box,right_box]))\n",
        "else:\n",
        "  print(\"No Cluster fields selected!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lyqTIu-wLjDD"
      },
      "outputs": [],
      "source": [
        "#@title (optional) Set Cluster colors\n",
        "#@markdown >Note: only necessary if categorical data was assigned for clusters\n",
        "\n",
        "if len(classColumns.value) > 0:\n",
        "  classColorDict = {}\n",
        "  amount = len(classColumns.value)\n",
        "  styleCol = {'description_width': '25px'}\n",
        "  layoutCl = {'width': '135px'}\n",
        "  allClasses = {}\n",
        "  for className in classColumns.value:\n",
        "    clusters = metadata[className].unique()\n",
        "    allClasses[className] = len(clusters)\n",
        "  l = sorted(allClasses.items(), key=lambda item: item[1])[0]\n",
        "  length = l[1]\n",
        "  allColors = {}\n",
        "  colors = distinctipy.get_colors(length)\n",
        "  col = 5\n",
        "  row = math.ceil(length/col)\n",
        "  i=0\n",
        "  rows = []\n",
        "  for r in range(0,col):\n",
        "    newRow = []\n",
        "    for c in range(0,row):\n",
        "      # classColorDict[className] = widgets.ColorPicker(concise=True, value=distinctipy.get_hex(colors[i]))\n",
        "      if i < len(colors):\n",
        "        allColors[i] = widgets.ColorPicker(concise=False, description=str(i), value=distinctipy.get_hex(colors[i]),layout=layoutCl,style=styleCol)\n",
        "        newRow.append(allColors[i])\n",
        "        i+=1\n",
        "    rows.append(VBox([nr for nr in newRow]))\n",
        "  display(HBox(rows))\n",
        "else:\n",
        "  allColors = False\n",
        "  print(\"No cluster was selected.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eDcpx2pwCQYT"
      },
      "outputs": [],
      "source": [
        "#@title Create metadata.json\n",
        "#@markdown Creates and saves the metadata.json file\n",
        "#@markdown >Note: This step is necessary!\n",
        "\n",
        "\n",
        "# modify image paths\n",
        "\n",
        "try:\n",
        "  sliderCols\n",
        "except NameError:\n",
        "  sliderCols = list(sliderColumns.value)\n",
        "\n",
        "imageFolder = f'public/datasets/{foldername}/images/'\n",
        "if useExample.value == True:\n",
        "  metadata[\"URL\"] = metadata[filenameColumn.value]\n",
        "else:\n",
        "  metadata[\"URL\"] = imageFolder + metadata[filenameColumn.value]\n",
        "metadataColumns = set(list(infoColumns.value) + sliderCols + list(filterColumns.value) + list(classColumns.value))\n",
        "metadataColumns.add(filenameColumn.value)\n",
        "metadata = metadata[metadataColumns]\n",
        "metadata.reset_index(inplace=True)\n",
        "# save metadata file\n",
        "result = metadata.to_json(orient=\"records\")\n",
        "with open(f'CSN/{foldername}/metadata.json', \"w\") as f:\n",
        "    f.write(result)\n",
        "print(\"saved metadata.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nu88VZMUR8Km"
      },
      "outputs": [],
      "source": [
        "#@title Calculate Histograms and create config files\n",
        "#@markdown The CSN features Range Sliders with interactive histograms. This step calculates the necessary bins and prepares the data to display the histograms.\n",
        "try:\n",
        "    sliderCols\n",
        "except NameError:\n",
        "    sliderCols = list(sliderColumns.value)\n",
        "\n",
        "def prepareBuckets(MIN,MAX, data):\n",
        "    # prepare Slider Bar Historgram\n",
        "    buckets = {}\n",
        "    bucketsSize = {}\n",
        "    bucketCount = 50\n",
        "    if (MIN < 0):\n",
        "        stepSize = (abs(MIN) + abs(MAX)) / bucketCount\n",
        "    else:\n",
        "        stepSize = abs((abs(MIN) - abs(MAX)) / bucketCount)\n",
        "    for i in range(0, bucketCount):\n",
        "        buckets[i] = []\n",
        "        bucketsSize[i] = 0\n",
        "    for index, e in enumerate(data):\n",
        "        if (e == MAX):\n",
        "            targetBucket = bucketCount-1\n",
        "        else:\n",
        "            targetBucket = math.floor((e - MIN) / stepSize)\n",
        "        buckets[targetBucket].append(index)\n",
        "        bucketsSize[targetBucket]+=1\n",
        "    return {\"histogram\":list(bucketsSize.values()), \"selections\":list(buckets.values()), \"range\":[int(MIN),int(MAX)]}\n",
        "\n",
        "def getBarChartData(df, selectionList):\n",
        "    bucketData =  {} \n",
        "    for element in selectionList:\n",
        "        print(\"preparing Slider Bar Historgram data\", element)\n",
        "        bucketData[element] = {str(element):{\"histogram\":[], \"selections\":[]}}\n",
        "        bucketData[element] = prepareBuckets(df[element].min(),df[element].max(), df[element].values.tolist())\n",
        "    return bucketData\n",
        "\n",
        "def update_config(metadata,mappings):\n",
        "    configData = {\"title\": datasetTitle.value, \"datasetInfo\": description.value, \"metadata\": \"metadata.json\", \"embeddings\": []}\n",
        "    if mappings:\n",
        "        configData[\"embeddings\"] = mappings    \n",
        "    configData[\"clusters\"] = clusters\n",
        "    configData[\"total\"] = len(metadata)\n",
        "    if tileSize:\n",
        "        configData[\"sprite_side\"] = tileRows\n",
        "        configData[\"sprite_number\"] = numbTiles\n",
        "        configData[\"sprite_image_size\"] = squareSize\n",
        "        configData[\"sprite_actual_size\"] = tileSize\n",
        "    configData[\"sliders\"] = sliderSetting\n",
        "    if infoColumns.value:\n",
        "        configData[\"info\"] = infoColumns.value\n",
        "    configData[\"search\"] = searchFields\n",
        "    if imageWebLocation.value.endswith(\"/\"):\n",
        "        configData[\"url_prefix\"] = imageWebLocation.value\n",
        "    else:\n",
        "        configData[\"url_prefix\"] = imageWebLocation.value + \"/\"\n",
        "\n",
        "    return configData\n",
        "\n",
        "def save_datasetsJSON():\n",
        "  with open(f'CSN/datasets_config.json', \"w\") as fd:\n",
        "    json.dump(datasetsJSON , fd)\n",
        "  print(\"saved datasets_config.json\")\n",
        "\n",
        "def make_default(DEFAULT):\n",
        "  datasetsJSON[\"default\"] = DEFAULT\n",
        "  print(f\"changed default dataset to {datasetsJSON['data'][DEFAULT]['name']}\")\n",
        "  save_datasetsJSON()\n",
        "  \n",
        "BarChartData = getBarChartData(metadata,sliderCols)\n",
        "with open(f'CSN/{foldername}/barData.json', \"w\") as f:\n",
        "    json.dump(BarChartData , f)\n",
        "print(f'saved barData.json')\n",
        "\n",
        "sliderSetting = []\n",
        "\n",
        "for k in sliderCols:\n",
        "  dtype = 'float'\n",
        "  if pd.api.types.is_integer_dtype(metadata[k]):\n",
        "    dtype = 'int'\n",
        "  slider = {\"id\":k,\"title\":sliderNameDict[k].value,\"info\":sliderInfoDict[k].value,\"typeNumber\":dtype,\"color\":sliderColorDict[k].value}\n",
        "  sliderSetting.append(slider)\n",
        "searchFields = []\n",
        "for k in filterColumns.value:\n",
        "  filter = {\"columnField\":k,\"type\":\"selection\"}\n",
        "  searchFields.append(filter)\n",
        "try:\n",
        "    allColors\n",
        "except NameError:\n",
        "    clusters = {\"clusterList\":[],\"clusterColors\":[]}\n",
        "else:\n",
        "    clusters = {\"clusterList\":list(classColumns.value),\"clusterColors\":[allColors[g].value for g in allColors]}\n",
        "\n",
        "configData = update_config(metadata,mappings)\n",
        "with open(f'CSN/{foldername}/config.json', \"w\") as fb:\n",
        "    json.dump(configData , fb)\n",
        "print(f'saved config.json')\n",
        "newDataset = {'name': datasetTitle.value, 'directory': foldername}\n",
        "\n",
        "datasetsJSON = {\"default\": 0, \"data\": [newDataset]}\n",
        "save_datasetsJSON()\n",
        "\n",
        "print(\"\\nContinue with building the Collection Space Navigator in the next step...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcRP9nmafoc7"
      },
      "source": [
        "----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5sixPIZr16X"
      },
      "source": [
        "<font size=6> 5) Build and use your custom Collection Space Navigator\n",
        "\n",
        "Creates the final CSN tool and provides different options to test or use it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GSZRq74yBzWX"
      },
      "outputs": [],
      "source": [
        "#@title Build custom CSN\n",
        "#@markdown >Note: This step pulls the build folder from the official Github repository (https://github.com/Collection-Space-Navigator/CSN)\n",
        "import shutil\n",
        "\n",
        "# if not os.path.exists(\"\"):\n",
        "#     os.makedirs(\"CSN\")\n",
        "#     print(\"created new directory 'CSN'\")\n",
        "\n",
        "print(\"pulling Collection Space Navigator from GitHub\")\n",
        "%cd CSN\n",
        "!git init\n",
        "!git remote add -f origin https://github.com/Collection-Space-Navigator/CSN\n",
        "!git config core.sparseCheckout true\n",
        "!echo \"build\" >> .git/info/sparse-checkout\n",
        "!git read-tree -mu HEAD\n",
        "!git pull origin main\n",
        "%cd -\n",
        "\n",
        "print(\"moving dataset to the Collection Space Navigator\")\n",
        "shutil.move(f\"CSN/{foldername}\", f\"CSN/build/datasets/{foldername}\")\n",
        "shutil.move(f\"CSN/datasets_config.json\", f\"CSN/build/datasets/datasets_config.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y0GYnYFtjHig"
      },
      "outputs": [],
      "source": [
        "#@title (optional) Download\n",
        "#@markdown >Note: Download your CSN version 'CSN_build.zip' to use it locally. Only needed in Google Colab.\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "!7z a CSN/CSN_build.zip CSN/build\n",
        "\n",
        "files.download('/content/CSN/CSN_build.zip')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IzISmA5UTmE9"
      },
      "outputs": [],
      "source": [
        "#@title (optional) Run proxy server in Google Colab (for quick testing)\n",
        "#@markdown >Note: **This will run in Colab until stopped!** Sharing the link won't work and it might be a bit slow. Connection will close after few minutes.\n",
        "\n",
        "try:\n",
        "  from flask import Flask, render_template,send_from_directory\n",
        "except:\n",
        "  print(\"Installing flask via Pip\")\n",
        "  !pip install flask\n",
        "  from flask import Flask, render_template,send_from_directory\n",
        "  \n",
        "\n",
        "import portpicker\n",
        "import threading\n",
        "import socket\n",
        "import http.server\n",
        "import socketserver\n",
        "from functools import partial\n",
        "from google.colab import output\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "def server_entry():\n",
        "    Handler = partial(http.server.SimpleHTTPRequestHandler, directory='/content/CSN/build')              \n",
        "    httpd = socketserver.TCPServer((\"\", port), Handler)\n",
        "    # Handle a single request then exit the thread.\n",
        "    httpd.serve_forever()\n",
        "\n",
        "port = portpicker.pick_unused_port()\n",
        "thread = threading.Thread(target=server_entry)\n",
        "thread.start()\n",
        "output.serve_kernel_port_as_window(port)\n",
        "port = portpicker.pick_unused_port()\n",
        "proxy_URL = eval_js(\"google.colab.kernel.proxyPort(%d)\" %port)\n",
        "\n",
        "print(\"\")\n",
        "print(20*'#')\n",
        "print(\"\")\n",
        "print(f\"Use this url: {proxy_URL}\")\n",
        "print(\"\")\n",
        "print(20*'#')\n",
        "print(\"\")\n",
        "print('starting server...')\n",
        "print('Note: this will run in Colab until stopped!')\n",
        "\n",
        "\n",
        "app = Flask(__name__,static_folder='/content/CSN/build/static',template_folder='/content/CSN/build')\n",
        "\n",
        "@app.route('/<path:path>')\n",
        "def send_report(path):\n",
        "  # remove the replace in next to lines later later <-- important !!!!!!!!\n",
        "  print(\"files\",path)\n",
        "  return send_from_directory('/content/CSN/build/', str(path))\n",
        "\n",
        "@app.route('/CSN/static/<path:path>')\n",
        "def send_report2(path):\n",
        "  # remove the replace in next to lines later later <-- important !!!!!!!!\n",
        "  print(\"files\",path)\n",
        "  return send_from_directory('/content/CSN/build/static/', str(path))\n",
        "\n",
        "@app.route('/CSN/datasets/<path:path>')\n",
        "def send_report3(path):\n",
        "  # remove the replace in next to lines later later <-- important !!!!!!!!\n",
        "  print(\"files\",path)\n",
        "  return send_from_directory('/content/CSN/build/datasets/', str(path))\n",
        "\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "  app.run(debug=False, port=port)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XgEk2EG9jXyy"
      },
      "outputs": [],
      "source": [
        "#@title (optional) Run ngrok server\n",
        "ngrok_Authtoken = 'YOUR_NGROK_TOKEN' #@param {type:\"string\"}\n",
        "#@markdown >Note: **This will run until stopped!** Requieres an ngrok account. See: https://ngrok.com/\n",
        "\n",
        "try:\n",
        "  from pyngrok import ngrok\n",
        "  from flask_ngrok import run_with_ngrok\n",
        "  from flask import Flask, render_template,send_from_directory\n",
        "except:\n",
        "  print(\"Installing flask, flask_ngrok and pyngrok via Pip\")\n",
        "  !pip install flask flask_ngrok pyngrok\n",
        "  from flask import Flask, render_template,send_from_directory\n",
        "  from pyngrok import ngrok\n",
        "  from flask_ngrok import run_with_ngrok\n",
        "  \n",
        "app = Flask(__name__,static_folder='/content/CSN/build/',template_folder='/content/CSN/build/')\n",
        "\n",
        "ngrok.set_auth_token(ngrok_Authtoken)\n",
        "run_with_ngrok(app)\n",
        "@app.route('/<path:path>')\n",
        "def send_report(path):\n",
        "  # remove the replace in next to lines later later <-- important !!!!!!!!\n",
        "  print(\"files\",path)\n",
        "  return send_from_directory('/content/CSN/build/', str(path))\n",
        "\n",
        "@app.route('/CSN/static/<path:path>')\n",
        "def send_report2(path):\n",
        "  # remove the replace in next to lines later later <-- important !!!!!!!!\n",
        "  print(\"files\",path)\n",
        "  return send_from_directory('/content/CSN/build/static/', str(path))\n",
        "  \n",
        "@app.route('/CSN/datasets/<path:path>')\n",
        "def send_report3(path):\n",
        "  # remove the replace in next to lines later later <-- important !!!!!!!!\n",
        "  print(\"files\",path)\n",
        "  return send_from_directory('/content/CSN/build/datasets/', str(path))\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "  app.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imqkuAZRiRIB"
      },
      "source": [
        "## (optional) Run in localhost\n",
        "\n",
        ">Note: only works locally (not within Colab)\n",
        "\n",
        "To run your CSN version on localhost, unzip your downloaded file, open a terminal, navigate to your CSN directory and run `serve -s build`\n",
        "\n",
        "The CSN should be then accessible at http://localhost:3000 in your browser.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zyht2IFkpWT"
      },
      "source": [
        "### (optional) Use as production web tool\n",
        "\n",
        "We recommend to use GitHub for hosting your custom CSN version and an external server for hosting your image collection. Note that GitHub limits any dataset to 1000 files.\n",
        "\n",
        "To deploy your version as a web tool in GitHub:\n",
        "\n",
        ">Note: Make sure your GitHub branch is called `gh-pages` and has the GitHub Pages option set. See more about GitHub Pages here: https://pages.github.com/\n",
        "\n",
        "1. clone the official CSN repository: https://github.com/Collection-Space-Navigator/CSN\n",
        "2. install NVM: https://github.com/nvm-sh/nvm\n",
        "3. install `node 14.21.2`: by running `nvm install v14.21.2`\n",
        "4. replace the `CSN/build` folder with your own\n",
        "5. in `package.json,` change `\"homepage\": \"https://collection-space-navigator.github.io/CSN\"` to your GitHub pages address\n",
        "6. deploy the build folder to your GitHub pages by running `npm run deploy`\n",
        "\n",
        "For more information and other deployment options, see https://create-react-app.dev/docs/deployment/\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "894f073ee313a387d8ab0b54a40d2928fe73692ba23550c72584c9df3304ca06"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}