{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeU25AnsCQYG"
      },
      "source": [
        "# Setting up the Collection Space Navigator\n",
        "### configuration and data files for custom collections and research needs\n",
        "In this How-To guide you will produce all necessary files for the Collection Space Navigator (CSN).:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcWeuOxUCQYI"
      },
      "source": [
        "## 1) Load & Prepare Collection Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc6tNJ5xCQYI"
      },
      "source": [
        "#### import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w25_J6m4CQYJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json, math, os, io\n",
        "from tqdm import tqdm\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interactive,HBox,VBox,Label\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wP2teI8CQYK"
      },
      "source": [
        "### define INPUT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6jZRVHhCQYK"
      },
      "outputs": [],
      "source": [
        "def mount_gdrive(v):\n",
        "    try:\n",
        "      from google.colab import drive\n",
        "      # drive.mount(drive_path,force_remount=False)\n",
        "      buttonGDrive.description=\"mounting...\"\n",
        "      buttonGDrive.disabled=True\n",
        "      drive.mount('/content/gdrive',force_remount=True)\n",
        "    except:\n",
        "      print(\"...error mounting drive\")\n",
        "      buttonGDrive.description=\"mounting failed!\"\n",
        "    else:\n",
        "      buttonGDrive.description=\"successfully mounted\"\n",
        "      \n",
        "def getOptions(USAGE, BUILD, EXIST, EXAMPLE):\n",
        "  if BUILD == 2:\n",
        "    uploadFile.disabled=False\n",
        "  else:\n",
        "    uploadFile.disabled=True\n",
        "  if EXIST == 1:\n",
        "    embeddingsLocation.disabled=False\n",
        "  else:\n",
        "    embeddingsLocation.disabled=True\n",
        "  if USAGE == 3:\n",
        "    buttonGDrive.disabled = False\n",
        "    imageWebLocation.disabled = True\n",
        "    imageLocation.value = \"/content/gdrive/MyDrive/YOUR-IMAGE-PATH\"\n",
        "    embeddingsLocation.value = \"/content/gdrive/MyDrive/YOUR-EMBEDDINGS-PATH\"\n",
        "    metadataLocation.value = \"/content/gdrive/MyDrive/YOUR-METADATA-PATH\"   \n",
        "  else:\n",
        "    buttonGDrive.disabled = True\n",
        "    imageWebLocation.disabled=False\n",
        "    imageLocation.value = ''\n",
        "    embeddingsLocation.value = ''\n",
        "    metadataLocation.value = ''   \n",
        "  if USAGE == 1:\n",
        "    imageWebLocation.value = \"http://localhost:3000/\"\n",
        "  if EXAMPLE == True:\n",
        "    buttonGDrive.disabled = True\n",
        "    imageWebLocation.disabled = False\n",
        "    datasetTitle.value = \"Testset\"\n",
        "    imageLocation.value = \"CSN/example_data/testset_images/\"\n",
        "    embeddingsLocation.value = \"CSN/example_data/embeddings_testset.csv\"\n",
        "    metadataLocation.value = \"CSN/example_data/metadata_testset.csv\"  \n",
        "    imageWebLocation.value =  \"https://github.com/Collection-Space-Navigator/CSN/raw/main/example_data/testset_images/\"\n",
        "\n",
        "style = {'description_width': '250px'}\n",
        "layout = {'width': '600px', 'justify-content': 'lex-satrt'}\n",
        "layoutButtons = {'width': '210px'}\n",
        "usage = widgets.Dropdown(options=[('locally on machine (offline)',1), ('as web tool (for production)',2), ('in Colab (for testing)',3)],value=3,description='Usage:',style=style,layout=layout)\n",
        "existingEmbeddings = widgets.RadioButtons(options=[('use own file',1), ('extract features',2)],value=1,description='Embeddings:',style=style, layout=layout)\n",
        "useExample = widgets.Checkbox(value=False,description='use example data',indent=True, style=style, layout=layout)\n",
        "datasetTitle = widgets.Text(placeholder='title of the dataset', description='Title:', style=style, layout=layout)\n",
        "description = widgets.Textarea(placeholder='Short description of the dataset and method(s)', description='Description (optional):', style=style, layout=layout)\n",
        "embeddingsLocation = widgets.Text(placeholder='path to embeddings file (.csv)', description='Embeddings Filepath:', style=style, layout=layout)\n",
        "metadataLocation = widgets.Text(placeholder='path to metadata file (.csv)', description='Metadata Filepath:', style=style, layout=layout)\n",
        "imageLocation = widgets.Text(placeholder='path to image collection folder', description='Image Folder:', style=style, layout=layout)\n",
        "imageWebLocation = widgets.Text(placeholder='URL to images (available online)', description='Image URL:', value = '',style=style, layout=layout)\n",
        "buildTool = widgets.RadioButtons(options=[('create new tool and dataset',1), ('add new dataset to existing tool',2)],value=1,description='Building:',style=style, layout=layout)\n",
        "uploadFile = widgets.FileUpload(accept='.json',multiple=False,description=\"upload 'datasets_config.json'\", layout=layoutButtons)\n",
        "buttonGDrive = widgets.Button(description='mount Google Drive',icon='check',layout=layoutButtons)\n",
        "buttonGDrive.on_click(mount_gdrive)\n",
        "i = interactive(getOptions, USAGE = usage, BUILD = buildTool, EXIST = existingEmbeddings, EXAMPLE = useExample)\n",
        "left = VBox([i, datasetTitle, description, embeddingsLocation, metadataLocation, imageLocation, imageWebLocation])\n",
        "right = VBox([buttonGDrive,uploadFile])\n",
        "display(HBox([left,right]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie3gEy1WRGek"
      },
      "source": [
        "#### load INPUT files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTpXZgnIXDVu"
      },
      "outputs": [],
      "source": [
        "if useExample.value == True:\n",
        "  if not os.path.exists(\"CSN\"):\n",
        "    os.makedirs(\"CSN\")\n",
        "    print(\"created new directory 'CSN'\")\n",
        "  if not os.path.exists(\"example_data\"):\n",
        "    %cd CSN\n",
        "    !git init\n",
        "    !git remote add -f origin https://github.com/Collection-Space-Navigator/CSN\n",
        "    !git config core.sparseCheckout true\n",
        "    !echo \"example_data\" >> .git/info/sparse-checkout\n",
        "    print(\"downloading example dataset...\")\n",
        "    !git pull origin main\n",
        "    print(\"...done\")\n",
        "    %cd -\n",
        "\n",
        "if buildTool.value == 2:\n",
        "  try:\n",
        "    uploaded_file = uploadFile.value[\"datasets_config.json\"]\n",
        "  except:\n",
        "     print(\"ERROR: uploaded file must be'datasets_config.json'!\")\n",
        "  else:\n",
        "    datasetsJSON = json.load(io.BytesIO(uploaded_file['content']))\n",
        "    if datasetsJSON['data']:\n",
        "      print(\"'datasets_config.json' looks ok.\")\n",
        "    else:\n",
        "      print(\"ERROR: 'datasets_config.json' seems to be broken!\")\n",
        "imagNumb = len(os.listdir(imageLocation.value))\n",
        "print(f'found {imagNumb} files in {imageLocation.value}')\n",
        "if existingEmbeddings.value == 1:\n",
        "  embeddings = pd.read_csv(embeddingsLocation.value, skipinitialspace=True)\n",
        "  embeddings = embeddings.loc[:, embeddings.columns!='id'] # for testing, delete later!!!!\n",
        "  vecNumb = len(embeddings)\n",
        "  print(f'found {vecNumb} entries in {embeddingsLocation.value}')\n",
        "metadata = pd.read_csv(metadataLocation.value, skipinitialspace=True)\n",
        "metaNumb = len(metadata)\n",
        "print(f'found {metaNumb} entries in {metadataLocation.value}')\n",
        "if existingEmbeddings.value == 1:\n",
        "  if metaNumb == vecNumb:\n",
        "    if vecNumb <= imagNumb:\n",
        "      print(\"Looks ok.\")\n",
        "      print()\n",
        "      print(f'Embedding file contains {vecNumb} vectors in {len(embeddings.columns)} dimensions.')\n",
        "      print(\"Metadata Head:\")\n",
        "      print(metadata.head())\n",
        "    else:\n",
        "      print()\n",
        "      print(\"ERROR: number of images is smaller than number of vectors\")\n",
        "else:\n",
        "  if metaNumb <= imagNumb:\n",
        "    print(\"Looks ok.\")\n",
        "    print(\"Metadata Head:\")\n",
        "    print(metadata.head())\n",
        "  else:\n",
        "    print()\n",
        "    print(\"ERROR: number of images and metadata elements don't match!\")\n",
        "foldername = datasetTitle.value.lower().replace(\" \",\"_\")\n",
        "print()\n",
        "print(f'Creating new dataset directory: {foldername}...')\n",
        "if not os.path.exists(foldername):\n",
        "    os.makedirs(foldername)\n",
        "    print(\"... success\")\n",
        "else:\n",
        "    print(\"... folder already exists (might overwrite existing files)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYj__oeqCQYR"
      },
      "source": [
        "#### Assign metadata fields\n",
        "Select which field names in the metadata file should be used. Multiple values can be selected with shift and/or ctrl (or command) pressed and mouse clicks or arrow keys."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtOUyvwapOfx"
      },
      "outputs": [],
      "source": [
        "filenameColumn = widgets.Dropdown(description=\"Image filenames:\",options=list(metadata.columns), style=style, layout=layout)\n",
        "classColumns = widgets.SelectMultiple(options=list(metadata.columns),description='optional: Cluster data (integers):', style=style, layout=layout)\n",
        "infoColumns = widgets.SelectMultiple(options=list(metadata.columns),description='Info fields (display in preview):', style=style, layout=layout)\n",
        "sliderColumns = widgets.SelectMultiple(options=list(metadata.columns),description='Slider data (floats or integers):', style=style, layout=layout)\n",
        "filterColumns = widgets.SelectMultiple(options=list(metadata.columns),description='optional: Filter & Search fields:', style=style, layout=layout)\n",
        "if useExample.value == True:\n",
        "  infoColumns.value = (\"Prompt\", \"Colors\", \"Contrast\", \"File Size\")\n",
        "  sliderColumns.value = (\"Colorfulness\", \"Colors\", \"Contrast\", \"File Size\")\n",
        "  filterColumns.value = (\"Prompt\",)\n",
        "  classColumns.value = (\"Class\",)\n",
        "left = VBox([filenameColumn, infoColumns, sliderColumns])\n",
        "right = VBox([filterColumns, classColumns])\n",
        "display(HBox([left,right]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5y2V_w4wZ_G"
      },
      "source": [
        "#### check if data types are correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-G0vlEWjuuCd"
      },
      "outputs": [],
      "source": [
        "error = False\n",
        "print(\"checking Image Filenames field...\")\n",
        "if pd.api.types.is_string_dtype(metadata[filenameColumn.value]) and metadata[filenameColumn.value].str.endswith((\".jpg\",\".JPEG\",\"JPG\",\".jpeg\",\".png\",\".PNG\")).all():\n",
        "  print(f\"...'{filenameColumn.value}' looks ok.\")\n",
        "else:\n",
        "  print(f\"ERROR: metadata field '{filenameColumn.value}' doesn't seem right. All values need to be jpeg or png image filenames!\")\n",
        "  error = True\n",
        "print(\"checking Info fields...\")\n",
        "if len(infoColumns.value) > 0:\n",
        "  print(f\"... looks ok.\")\n",
        "  print(f\"CSN will provide info on: {infoColumns.value}\")\n",
        "else:\n",
        "  print(f\"...no Info fields selected!\")\n",
        "print(\"checking Sliders fields...\")\n",
        "for col in sliderColumns.value:\n",
        "  if not pd.api.types.is_numeric_dtype(metadata[col]):\n",
        "    print(f\"ERROR: metadata field '{col}' doesn't seem right. Data type for Sliders must be integer or float!\")\n",
        "    error = True\n",
        "  else:\n",
        "    print(f\"...'{col}' looks ok.\")\n",
        "print(\"checking Filter & Search fields...\")\n",
        "if len(filterColumns.value) > 0:\n",
        "  print(f\"... looks ok.\")\n",
        "  print(f\"CSN will use the follwing fields for queries: {filterColumns.value}\")\n",
        "else:\n",
        "  print(f\"...no Filter & Search fields selected!\")\n",
        "print(\"checking Cluster fields...\")\n",
        "if len(classColumns.value) > 0:\n",
        "  for col in classColumns.value:\n",
        "    if not pd.api.types.is_integer_dtype(metadata[col]):\n",
        "      print(f\"ERROR: metadata field '{col}' doesn't seem right. Data type for Cluster must be integer!\")\n",
        "      error = True\n",
        "    else:\n",
        "      print(f\"...'{col}' looks ok.\")\n",
        "else:\n",
        "  print(f\"...no Cluster fields selected!\")\n",
        "if error == False:\n",
        "  print(\"\\nEverything looks good!\")\n",
        "else:\n",
        "  print(\"\\nFound some errors! Please fix before you continue.\")\n",
        "  \n",
        "sliderCols = list(sliderColumns.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsSJ7w-2X5LK"
      },
      "source": [
        "#### Process metadata and save file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDcpx2pwCQYT"
      },
      "outputs": [],
      "source": [
        "# modify image paths\n",
        "if usage.value == 2:\n",
        "  imageFolder = ''\n",
        "else:\n",
        "  imageFolder = f'public/datasets/{foldername}/images/'\n",
        "if useExample.value == True:\n",
        "  metadata[\"URL\"] = imageWebLocation.value + metadata[filenameColumn.value]\n",
        "else:\n",
        "  metadata[\"URL\"] = imageWebLocation.value + imageFolder + metadata[filenameColumn.value]\n",
        "# save metadata file\n",
        "result = metadata.to_json(orient=\"records\")\n",
        "with open(f'{foldername}/metadata.json', \"w\") as f:\n",
        "    f.write(result)\n",
        "print(\"saved metadata.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHx6vy1ACQYU"
      },
      "source": [
        "## 2) Generate Image Tiles  \n",
        "To handle large amounts of images efficiently, the CSN loads the files in form of optimized tiles. This step generates them.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzQaiLkUQC62"
      },
      "outputs": [],
      "source": [
        "# parameters for tiles\n",
        "tileSize = 2048  # size of tile\n",
        "tileRows = 32  # rows per tile\n",
        "columns = tileRows  # columns per tile\n",
        "squareSize = int(tileSize/tileRows)\n",
        "imgPerTile = tileRows*columns\n",
        "numbTiles = math.ceil(len(metadata)/imgPerTile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFaiNjp7QaeR"
      },
      "source": [
        "> Note: Only needed for new datasets or to update existing tiles.  \n",
        "Skip this part if you already generated them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBSPbVtXCQYU"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def generateTiles(ImgPaths,foldername,IMAGE_FOLDER):\n",
        "    tileNumb = 0\n",
        "    currentIDX = 0\n",
        "    if not IMAGE_FOLDER.endswith(\"/\"):\n",
        "      IMAGE_FOLDER += \"/\"\n",
        "    result = Image.new(\"RGBA\", (tileSize, tileSize), (255, 0, 0, 0))\n",
        "    for entry in tqdm(ImgPaths, desc = \"Generating tiles\"):\n",
        "        if currentIDX > imgPerTile:\n",
        "            result = result.resize((tileSize, tileSize), Image.ANTIALIAS)\n",
        "            result.save(f'{foldername}/tile_{tileNumb}.png', \"PNG\")\n",
        "            # new tile\n",
        "            currentIDX = 0\n",
        "            tileNumb += 1\n",
        "            result = Image.new(\"RGBA\", (tileSize, tileSize), (0, 0, 0, 0))\n",
        "        else:\n",
        "            try:\n",
        "                image = Image.open(IMAGE_FOLDER + entry) \n",
        "            except Exception as e: \n",
        "                print(e)\n",
        "            else:\n",
        "                (w,h) = image.size\n",
        "                # portrait format\n",
        "                if (h > w):\n",
        "                    w = int(w/h*squareSize)\n",
        "                    h = squareSize\n",
        "                    x_dif = int((squareSize - w) / 2)\n",
        "                    y_dif = 0\n",
        "                # landscape or square format\n",
        "                else:\n",
        "                    h = int(h/w*squareSize)\n",
        "                    w = squareSize\n",
        "                    x_dif = 0\n",
        "                    y_dif = int((squareSize - h) / 2)\n",
        "                resizedImage = image.resize((w-8, h-8), Image.ANTIALIAS)       \n",
        "                r_result = Image.new(\"RGBA\", (w, h), (1, 1, 1, 1))   # produces an almost transparent border to indicate clusters in the tool\n",
        "                r_result.paste(resizedImage, (4,4))\n",
        "                x = currentIDX % tileRows * squareSize + x_dif\n",
        "                y = currentIDX // columns * squareSize + y_dif\n",
        "                result.paste(r_result, (x, y, x + w, y + h))\n",
        "                currentIDX += 1\n",
        "    result = result.resize((tileSize, tileSize), Image.ANTIALIAS)\n",
        "    result.save(f'{foldername}/tile_{tileNumb}.png', \"PNG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKiQWCQYY2mM"
      },
      "outputs": [],
      "source": [
        "generateTiles(metadata[filenameColumn.value],foldername,imageLocation.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvsa4czdCQYV"
      },
      "source": [
        "## 3) Generate Mappings\n",
        "\n",
        "Mappings are plots containing 2D coordinates (x,y) of the image objects. \n",
        "\n",
        "Here are several methods you can run. The Collection Space Navigator can handle many mappings but needs at least one to work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUKhZOLKCQYV"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "mappings = []\n",
        "minScale = -25\n",
        "maxScale = 25\n",
        "\n",
        "def normalize(embeddings):\n",
        "    minX = min(embeddings, key=lambda x: x[0])[0]\n",
        "    rangeX = max(embeddings, key=lambda x: x[0])[0] - minX\n",
        "    minY = min(embeddings, key=lambda x: x[1])[1]\n",
        "    rangeY = max(embeddings, key=lambda x: x[1])[1] - minY\n",
        "    rangeScale = maxScale + 0.9999999999 - minScale\n",
        "    for index, e in enumerate(embeddings):\n",
        "        embeddings[index][0] =  (embeddings[index][0] - minX) / rangeX * rangeScale + minScale\n",
        "        embeddings[index][1] = (embeddings[index][1] - minY) / rangeY * rangeScale + minScale\n",
        "    return embeddings\n",
        "\n",
        "def centerEmbeddings(embeddings):\n",
        "    offsetA = (max(embeddings, key=lambda x: x[0])[0] + min(embeddings, key=lambda x: x[0])[0]) / 2\n",
        "    offsetB = (max(embeddings, key=lambda x: x[1])[1] + min(embeddings, key=lambda x: x[1])[1]) / 2\n",
        "    for index, e in enumerate(embeddings):\n",
        "        embeddings[index][0] = embeddings[index][0] - offsetA\n",
        "        embeddings[index][1] = embeddings[index][1] - offsetB\n",
        "    return embeddings\n",
        "    \n",
        "class NumpyEncoder(json.JSONEncoder):\n",
        "    \"\"\" Special json encoder for numpy types \"\"\"\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return json.JSONEncoder.default(self, obj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTTmiLubnp1u"
      },
      "source": [
        "### PCA: Principal Component Analysis\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBwRz1RYnpUr"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def generate_PC(df,n,scale):\n",
        "    print(\"performing PCA...\")\n",
        "    x = StandardScaler().fit_transform(df)\n",
        "    pca = PCA(n_components=n)\n",
        "    embedding = pca.fit_transform(x)\n",
        "    if scale == True:\n",
        "      normalized = normalize(embedding)\n",
        "      centeredEmbedding = centerEmbeddings(normalized)\n",
        "    else:\n",
        "      centeredEmbedding = embedding\n",
        "    print(\"...done\")\n",
        "    return centeredEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPMQ3emspOdc"
      },
      "outputs": [],
      "source": [
        "PCAEembedding = generate_PC(embeddings,2,True)\n",
        "# save file\n",
        "with open(f'{foldername}/PCA.json', \"w\") as out_file:\n",
        "    out = json.dumps(PCAEembedding, cls=NumpyEncoder)\n",
        "    out_file.write(out)\n",
        "print(f\"saved PCA.json\")\n",
        "mappings.append({\"name\": \"PCA\", \"file\": \"PCA.json\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### !!! DOESN'T WORK - BREAKS TOOL !!! add Principal Components to metadata and Sliders"
      ],
      "metadata": {
        "id": "QtOl-41Bt1xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def addPC(ADD):\n",
        "#   if ADD == True:\n",
        "#     display(VBox([PCs,addButton]))\n",
        "\n",
        "# def PCButton(v):\n",
        "#   PCAEembedding = generate_PC(embeddings,PCs.value,False)\n",
        "#   print(\"adding to metadata and Slides...\")\n",
        "#   for PC in range(0,PCs.value):\n",
        "#     key = f\"PC{PC+1}\"\n",
        "#     metadata[key] = PCAEembedding[:,PC]\n",
        "#     sliderCols.append(key)\n",
        "#   print(\"...done\")\n",
        "\n",
        "# addPCA = widgets.Checkbox(value=False,description='add Principal Components',indent=True, style=style, layout=layout)\n",
        "# PCs = widgets.IntSlider(value=3,min=1,max=5,step=1,description='number of Components:',readout=True,readout_format='d', style=style, layout=layout)\n",
        "# addButton = widgets.Button(description='make PC data',icon='check', layout=layoutButtons)\n",
        "# addButton.on_click(PCButton)\n",
        "# display(interactive(addPC, ADD = addPCA))"
      ],
      "metadata": {
        "id": "Dxq0r9TxrNxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHoAHuWLCQYV"
      },
      "source": [
        "### UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction\n",
        "https://umap-learn.readthedocs.io/en/latest/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrJqZPjYCQYW"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import umap.umap_ as umap\n",
        "except:\n",
        "  print(\"Installing umap-learn via Pip\")\n",
        "  !pip install umap-learn --quiet\n",
        "  import umap.umap_ as umap\n",
        "\n",
        "# UMAP parameter\n",
        "n_neighbors=15\n",
        "min_dist=0.15\n",
        "metric=\"correlation\"\n",
        "verbose=True\n",
        "\n",
        "def generateUMAP(df):\n",
        "    print(\"generating UMAP...\")\n",
        "    scaled_penguin_data = StandardScaler().fit_transform(df)\n",
        "    reducer = umap.UMAP(n_neighbors=n_neighbors,\n",
        "                        min_dist=min_dist,\n",
        "                        metric=metric,\n",
        "                        verbose=verbose)\n",
        "    embedding = reducer.fit_transform(scaled_penguin_data)\n",
        "    normalized = normalize(embedding)\n",
        "    centeredEmbedding = centerEmbeddings(normalized)\n",
        "    print(\"...done\")\n",
        "    return centeredEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LG_58tHCQYW"
      },
      "outputs": [],
      "source": [
        "fullEmbeddings = generateUMAP(embeddings)\n",
        "# save file\n",
        "with open(f'{foldername}/UMAP.json', \"w\") as out_file:\n",
        "    out = json.dumps(fullEmbeddings, cls=NumpyEncoder)\n",
        "    out_file.write(out)\n",
        "print(f\"saved UMAP.json\")\n",
        "mappings.append({\"name\": \"UMAP\", \"file\": \"UMAP.json\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLIehXZvCQYX"
      },
      "source": [
        "### t-SNE: t-distributed Stochastic Neighbor Embedding\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NlqxmzVCQYX"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# t-SNE parameter\n",
        "n_components = 2\n",
        "verbose = 1\n",
        "random_state = 123\n",
        "\n",
        "def generateTSNE(df):\n",
        "    print(\"generating t-SNE...\")\n",
        "    x = StandardScaler().fit_transform(df)\n",
        "    tsne = TSNE(n_components=n_components, verbose=verbose, random_state=random_state)\n",
        "    embedding = tsne.fit_transform(x)\n",
        "    normalized = normalize(embedding)\n",
        "    centeredEmbedding = centerEmbeddings(normalized)\n",
        "    print(\"...done\")\n",
        "    return centeredEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USr5YEPvCQYX"
      },
      "outputs": [],
      "source": [
        "tsneEembedding = generateTSNE(embeddings)\n",
        "# save file\n",
        "with open(f'{foldername}/tSNE.json', \"w\") as out_file:\n",
        "    out = json.dumps(tsneEembedding, cls=NumpyEncoder)\n",
        "    out_file.write(out)\n",
        "print(f\"saved tSNE.json\")\n",
        "mappings.append({\"name\": \"t-SNE\", \"file\": \"tSNE.json\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNX8L9epCQYY"
      },
      "source": [
        "### 2D plots\n",
        "\n",
        "Choose 2 metadadata fields (float or integer) and click \"make plot\". Repeat for every combination you want to add."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sg3a8k_CQYY"
      },
      "outputs": [],
      "source": [
        "def makePlot(v):\n",
        "  A = AColumn.value\n",
        "  B = BColumn.value\n",
        "  if pd.api.types.is_numeric_dtype(metadata[A]):\n",
        "    print(f\"'{A}' looks ok\")\n",
        "    if pd.api.types.is_numeric_dtype(metadata[B]):\n",
        "      print(f\"'{B}' looks ok\")\n",
        "      plot = metadata[[A,B]]\n",
        "      normalizedPlot = normalize(plot.values)\n",
        "      centeredEmbedding = centerEmbeddings(normalizedPlot)\n",
        "      filename = (A + \"_\" + B).replace(\" \",\"\")\n",
        "      # save file\n",
        "      with open(f'{foldername}/{filename}.json', \"w\") as out_file:\n",
        "        out = json.dumps(centeredEmbedding, cls=NumpyEncoder)\n",
        "        out_file.write(out)\n",
        "      print(f\"saved {filename}.json\")\n",
        "      mappings.append({\"name\": filename, \"file\": filename + \".json\"})\n",
        "    else:\n",
        "      print(f\"ERROR: metadata field '{B}' doesn't seem right. Data type must be integer or float!\")\n",
        "  else:\n",
        "    print(f\"ERROR: metadata field '{A}' doesn't seem right. Data type must be integer or float!\")\n",
        "    \n",
        "AColumn = widgets.Dropdown(description=\"x-axis:\",options=list(metadata.columns), style=style, layout=layout)\n",
        "BColumn = widgets.Dropdown(description=\"y-axis:\",options=list(metadata.columns), style=style, layout=layout)\n",
        "button2DPlot = widgets.Button(description='make plot',icon='check')\n",
        "button2DPlot.on_click(makePlot)\n",
        "left = VBox([AColumn,BColumn])\n",
        "right = VBox([button2DPlot])\n",
        "HBox([left,right])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGMW_lhImNhC"
      },
      "source": [
        "## 4) Settings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNtf-UXVnTFn"
      },
      "source": [
        "#### Sliders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoSHLl1gCT8H"
      },
      "outputs": [],
      "source": [
        "if len(sliderCols) > 0:    \n",
        "  try:\n",
        "    import distinctipy\n",
        "  except:\n",
        "    print(\"Installing distinctipy via Pip\")\n",
        "    !pip install distinctipy --quiet\n",
        "    import distinctipy\n",
        "  layoutCol = {'width': '110px'}\n",
        "  sliderColorDict = {}\n",
        "  left = [Label('display name')]\n",
        "  middle = [Label('description text')]\n",
        "  right = [Label('histogram color')]\n",
        "  colors = distinctipy.get_colors(len(sliderCols),pastel_factor=1)\n",
        "  for i, sliderName in enumerate(sliderCols):\n",
        "    sliderColorDict[sliderName] = widgets.ColorPicker(concise=False,value=distinctipy.get_hex(colors[i]),layout=layoutCol)\n",
        "    right.append(sliderColorDict[sliderName])\n",
        "  sliderInfoDict = {}\n",
        "  for sliderName in sliderCols:\n",
        "    sliderInfoDict[sliderName] = widgets.Text(placeholder=\"info text for slider\",layout=layout)\n",
        "    middle.append(sliderInfoDict[sliderName])\n",
        "  sliderNameDict = {}\n",
        "  for sliderName in sliderCols:\n",
        "    sliderNameDict[sliderName] = widgets.Text(placeholder=\"name of slider\",value=sliderName)\n",
        "    left.append(sliderNameDict[sliderName])\n",
        "  print(\"\\nSlider Settings:\\n\") \n",
        "  idx = VBox([Label('')]+[Label(f\"{n}:\") for n in sliderCols])\n",
        "  left_box = VBox([l for l in left])\n",
        "  middle_box = VBox([m for m in middle])\n",
        "  right_box = VBox([r for r in right])\n",
        "  display(HBox([idx,left_box,middle_box,right_box]))\n",
        "else:\n",
        "  print(\"No Cluster fields selected!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBx8DBhGp5Jm"
      },
      "source": [
        "#### Cluster colors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyqTIu-wLjDD"
      },
      "outputs": [],
      "source": [
        "if len(classColumns.value) > 0:\n",
        "  classColorDict = {}\n",
        "  amount = len(classColumns.value)\n",
        "  styleCol = {'description_width': '25px'}\n",
        "  layoutCl = {'width': '135px'}\n",
        "  allClasses = {}\n",
        "  for className in classColumns.value:\n",
        "    clusters = metadata[className].unique()\n",
        "    allClasses[className] = len(clusters)\n",
        "  l = sorted(allClasses.items(), key=lambda item: item[1])[0]\n",
        "  length = l[1]\n",
        "  allColors = {}\n",
        "  colors = distinctipy.get_colors(length)\n",
        "  col = 5\n",
        "  row = math.ceil(length/col)\n",
        "  i=0\n",
        "  rows = []\n",
        "  for r in range(0,col):\n",
        "    newRow = []\n",
        "    for c in range(0,row):\n",
        "      # classColorDict[className] = widgets.ColorPicker(concise=True, value=distinctipy.get_hex(colors[i]))\n",
        "      if i < len(colors):\n",
        "        allColors[i] = widgets.ColorPicker(concise=False, description=str(i), value=distinctipy.get_hex(colors[i]),layout=layoutCl,style=styleCol)\n",
        "        newRow.append(allColors[i])\n",
        "        i+=1\n",
        "    rows.append(VBox([nr for nr in newRow]))\n",
        "  display(HBox(rows))\n",
        "else:\n",
        "  print(\"No cluster was selected.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7r2I7QzCQYa"
      },
      "source": [
        "## 5) Create/update Config Files\n",
        "\n",
        "All customization and component settings are defined in the config files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F24RZ8wiCQYZ"
      },
      "source": [
        "#### calculate and save histograms  \n",
        "The CSN Range Sliders come with interactive histograms. This step calculates the buckets and prepares the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pl4iXbQzCQYZ"
      },
      "outputs": [],
      "source": [
        "def prepareBuckets(MIN,MAX, data):\n",
        "    # prepare Slider Bar Historgram\n",
        "    buckets = {}\n",
        "    bucketsSize = {}\n",
        "    bucketCount = 50\n",
        "    if (MIN < 0):\n",
        "        stepSize = (abs(MIN) + abs(MAX)) / bucketCount\n",
        "    else:\n",
        "        stepSize = abs((abs(MIN) - abs(MAX)) / bucketCount)\n",
        "    for i in range(0, bucketCount):\n",
        "        buckets[i] = []\n",
        "        bucketsSize[i] = 0\n",
        "    for index, e in enumerate(data):\n",
        "        if (e == MAX):\n",
        "            targetBucket = bucketCount-1\n",
        "        else:\n",
        "            targetBucket = math.floor((e - MIN) / stepSize)\n",
        "        buckets[targetBucket].append(index)\n",
        "        bucketsSize[targetBucket]+=1\n",
        "    return {\"histogram\":list(bucketsSize.values()), \"selections\":list(buckets.values()), \"range\":[int(MIN),int(MAX)]}\n",
        "\n",
        "def getBarChartData(df, selectionList):\n",
        "    bucketData =  {} \n",
        "    for PC in selectionList:\n",
        "        print(\"preparing Slider Bar Historgram data\", PC)\n",
        "        bucketData[PC] = {str(PC):{\"histogram\":[], \"selections\":[]}}\n",
        "        bucketData[PC] = prepareBuckets(df[PC].min(),df[PC].max(), df[PC].values.tolist())\n",
        "    return bucketData\n",
        "\n",
        "def update_config(metadata,mappings):\n",
        "    configData = {\"title\": datasetTitle.value, \"datasetInfo\": description.value, \"metadata\": \"metadata.json\", \"embeddings\": []}\n",
        "    if mappings:\n",
        "        configData[\"embeddings\"] = mappings    \n",
        "    configData[\"clusters\"] = clusters\n",
        "    configData[\"total\"] = len(metadata)\n",
        "    if tileSize:\n",
        "        configData[\"sprite_side\"] = tileRows\n",
        "        configData[\"sprite_number\"] = numbTiles\n",
        "        configData[\"sprite_image_size\"] = squareSize\n",
        "        configData[\"sprite_actual_size\"] = tileSize\n",
        "    configData[\"sliders\"] = sliderSetting\n",
        "    if infoColumns.value:\n",
        "        configData[\"info\"] = infoColumns.value\n",
        "    configData[\"search\"] = searchFields\n",
        "    return configData\n",
        "\n",
        "def save_datasetsJSON():\n",
        "  with open(f'datasets_config.json', \"w\") as fd:\n",
        "    json.dump(datasetsJSON , fd)\n",
        "  print(\"saved datasets_config.json\")\n",
        "\n",
        "def make_default(DEFAULT):\n",
        "  datasetsJSON[\"default\"] = DEFAULT\n",
        "  print(f\"changed default dataset to {datasetsJSON['data'][DEFAULT]['name']}\")\n",
        "  save_datasetsJSON()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDPHQKnOR7mq"
      },
      "source": [
        "#### write histogram data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu88VZMUR8Km"
      },
      "outputs": [],
      "source": [
        "BarChartData = getBarChartData(metadata,sliderCols)\n",
        "with open(f'{foldername}/barData.json', \"w\") as f:\n",
        "    json.dump(BarChartData , f)\n",
        "print(f'saved barData.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgIMDnuPq_oj"
      },
      "source": [
        "#### write config files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDtS_81BX3lf"
      },
      "outputs": [],
      "source": [
        "sliderSetting = []\n",
        "def zip_folder(v):\n",
        "    buttonZip.description = \"...zipping dataset\"\n",
        "    buttonZip.disabled = True\n",
        "    !7z a {foldername}.zip {foldername}\n",
        "    print(f\"\\nDataset '{foldername}.zip' and 'datasets_config.json' are ready to download.\")\n",
        "    print(f\"Place the unpacked dataset folder in your local CSN directory 'public/datasets/' in development mode or in '/datasets/' in the build production.\")\n",
        "    print(f\"Also, replace 'datasets/datasets_config.json' with the new file.\")\n",
        "    buttonZip.description = \"zipping done\"\n",
        "\n",
        "for k in sliderCols:\n",
        "  dtype = 'float'\n",
        "  if pd.api.types.is_integer_dtype(metadata[k]):\n",
        "    dtype = 'integer'\n",
        "  slider = {\"id\":k,\"title\":sliderNameDict[k].value,\"info\":sliderInfoDict[k].value,\"typeNumber\":dtype,\"color\":sliderColorDict[k].value}\n",
        "  sliderSetting.append(slider)\n",
        "searchFields = []\n",
        "for k in filterColumns.value:\n",
        "  filter = {\"columnField\":k,\"type\":\"selection\"}\n",
        "  searchFields.append(filter)\n",
        "clusters = {\"clusterList\":list(classColumns.value),\"clusterColors\":[allColors[g].value for g in allColors]}\n",
        "configData = update_config(metadata,mappings)\n",
        "with open(f'{foldername}/config.json', \"w\") as fb:\n",
        "    json.dump(configData , fb)\n",
        "print(f'saved config.json')\n",
        "newDataset = {'name': datasetTitle.value, 'directory': foldername}\n",
        "if buildTool.value == 2:\n",
        "    if newDataset not in datasetsJSON[\"data\"]:\n",
        "      datasetsJSON[\"data\"].append(newDataset)\n",
        "    print(\"change default dataset:\")\n",
        "    defaultOptions = [(e[\"name\"],i) for i,e in enumerate(datasetsJSON[\"data\"])]\n",
        "    defaultDataset = widgets.Dropdown(description=\"Default dataset:\",options=defaultOptions, style=style, layout=layout)\n",
        "    defaulInteracive = interactive(make_default,DEFAULT = defaultDataset)\n",
        "    display(defaulInteracive)\n",
        "    # save_datasetsJSON()\n",
        "else:\n",
        "    datasetsJSON = {\"default\": 0, \"data\": [newDataset]}\n",
        "    save_datasetsJSON()\n",
        "if buildTool.value == 2:\n",
        "    buttonZip = widgets.Button(description='zip dataset',icon='check')\n",
        "    buttonZip.on_click(zip_folder)\n",
        "    display(buttonZip)\n",
        "else:\n",
        "    print(\"\\nContinue with building the Collection Space Navigator in the next step...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcRP9nmafoc7"
      },
      "source": [
        "----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5sixPIZr16X"
      },
      "source": [
        "## 6) Building custom Collection Space Navigator\n",
        "\n",
        "Depending on how you choose to run the CSN, we need to prepare the tool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POmuB-5jDAH3"
      },
      "source": [
        "#### Pull CSN from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"CSN\"):\n",
        "    os.makedirs(\"CSN\")\n",
        "    print(\"created new directory 'CSN'\")\n",
        "\n",
        "%cd CSN\n",
        "!git init\n",
        "!git remote add -f origin https://github.com/Collection-Space-Navigator/CSN\n",
        "!git config core.sparseCheckout true\n",
        "!echo \"build\" >> .git/info/sparse-checkout\n",
        "!git read-tree -mu HEAD\n",
        "!git pull origin main\n",
        "%cd -"
      ],
      "metadata": {
        "id": "GSZRq74yBzWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQPFxSlqhWbp"
      },
      "source": [
        "#### move the new Dataset to the Collection Space Navigator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzLKIt2PvcSD"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.move(f\"/content/{foldername}\", f\"/content/CSN/build/datasets/{foldername}\")\n",
        "shutil.move(f\"/content/datasets_config.json\", f\"/content/CSN/build/datasets/datasets_config.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkKoC0UeegRg"
      },
      "source": [
        "#### zip folder to download your version of the Collection Space Navigator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0GYnYFtjHig"
      },
      "outputs": [],
      "source": [
        "!7z a CSN_build.zip CSN/build\n",
        "print(\"download your CSN version 'CSN_build.zip'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCf7tEy_iSKt"
      },
      "source": [
        "## 7) Using the Collection Space Navigator\n",
        "\n",
        "depending on how you chose to use the tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9I4D4DEdVOf"
      },
      "outputs": [],
      "source": [
        "buildFolderPath = \"build\" # ToDo: create everything needed for local server to run\n",
        "webFolderPath = \"\" # ToDo: create everything needed for server to run as website\n",
        "if usage.value != 2:\n",
        "  print(f\"-> To run your CSN version locally, download the {buildFolderPath} folder and run the virtual server by running [] \\n\")\n",
        "if usage.value != 1:\n",
        "  print(f\"-> To run your CSN version as a web tool, download the {webFolderPath} folder and upload it to your server. \\n\")\n",
        "print(\"-> Continue with the next step to run your CSN version with a proxy server.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iJUHXoHeSbm"
      },
      "source": [
        "#### run a proxy server and test your CSN version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzISmA5UTmE9"
      },
      "outputs": [],
      "source": [
        "def run_server():\n",
        "  def server_entry():\n",
        "    from functools import partial\n",
        "    import socketserver, http.server\n",
        "    Handler = partial(http.server.SimpleHTTPRequestHandler, directory='/content/CSN/build/')              \n",
        "    httpd = socketserver.TCPServer((\"\", port), Handler)\n",
        "    # Handle a single request then exit the thread.\n",
        "    httpd.serve_forever()\n",
        "  import portpicker, threading, socket\n",
        "  port = portpicker.pick_unused_port()\n",
        "  thread = threading.Thread(target=server_entry)\n",
        "  thread.start()\n",
        "  from google.colab import output\n",
        "  print(f\"... ready!\")\n",
        "  print(f\"\\nUse the CSN here:\")\n",
        "  output.serve_kernel_port_as_window(port)\n",
        "def run_ngrok(ngrokAuthtoken):\n",
        "  try:\n",
        "    from pyngrok import ngrok\n",
        "    from flask_ngrok import run_with_ngrok\n",
        "    from flask import Flask, render_template,send_from_directory\n",
        "  except:\n",
        "    print(\"Installing flask, flask_ngrok and pyngrok via Pip\")\n",
        "    !pip install flask flask_ngrok pyngrok --quiet\n",
        "    from flask import Flask, render_template,send_from_directory\n",
        "    from pyngrok import ngrok\n",
        "    from flask_ngrok import run_with_ngrok\n",
        "  from multiprocessing import Process\n",
        "  app = Flask(__name__,static_folder='/content/CSN/build/',template_folder='/content/CSN/build/')\n",
        "  ngrok.set_auth_token(ngrokAuthtoken)\n",
        "  run_with_ngrok(app)\n",
        "  @app.route('/<path:path>')\n",
        "  def send_report(path):\n",
        "    # remove the replace in next to lines later later <-- important !!!!!!!!\n",
        "    print(\"files\",path)\n",
        "    return send_from_directory('/content/CSN/build/', str(path))\n",
        "  @app.route(\"/\")\n",
        "  def home():\n",
        "      return render_template('index.html')  \n",
        "  if __name__ == \"__main__\":\n",
        "    server = Process(target=app.run)\n",
        "    server.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQx06M8vJkVc"
      },
      "outputs": [],
      "source": [
        "def button_run(v):\n",
        "  if serverChoice.value == 1:\n",
        "    print(f\"\\nStarting your CSN version in colab...\")\n",
        "    buttonRun.description = '...running'\n",
        "    buttonRun.disabled = True\n",
        "    run_server()\n",
        "  else:\n",
        "    if len(ngrokKey.value)>10:\n",
        "      print(\"\\nRunning your CSN version with ngrok...\")\n",
        "      buttonRun.description = '...running'\n",
        "      buttonRun.disabled = True\n",
        "      run_ngrok(ngrokKey.value)\n",
        "    else:\n",
        "      print(\"\\nERROR: no ngrok authentication token found!\")\n",
        "def get_server(SERVER):\n",
        "  if SERVER == 1:\n",
        "    buttonRun.description = 'run colab proxy'\n",
        "    infoLabel = Label(\"colab proxy: The link only works until reloaded and can't be shared. Perfect for quick testing.\")\n",
        "    display(VBox([infoLabel,buttonRun]))\n",
        "  else:\n",
        "    buttonRun.description = 'run ngrok proxy'\n",
        "    infoLabel = Label(\"ngrok proxy: External service. The link works while running and can be shared with others.\")\n",
        "    warnLabel = Label(\"NOTE: This is NOT a solution for production (make web tool instead)! Needs registration -> https://ngrok.com/\")\n",
        "    display(VBox([ngrokKey,infoLabel,warnLabel,buttonRun]))\n",
        "serverChoice = widgets.Dropdown(description=\"run server:\",options=[(\"colab proxy\",1),(\"ngrok proxy\",2)])\n",
        "ngrokKey = widgets.Text(placeholder=\"authentication token from your ngrok account\",description=\"ngrok token:\",layout=layout)\n",
        "buttonRun = widgets.Button(description='run colab proxy',icon='check',disabled=False)\n",
        "buttonRun.on_click(button_run)\n",
        "interactive(get_server,SERVER = serverChoice)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqW8wRL_e0qD"
      },
      "outputs": [],
      "source": [
        "# for testing ngrok, don't ship!\n",
        "# 214xqlGaK4ILkWe0trnzvyD8CCo_zsbBD48amdfb6LQ9t7Kw "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "894f073ee313a387d8ab0b54a40d2928fe73692ba23550c72584c9df3304ca06"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}